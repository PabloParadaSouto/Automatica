{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PabloParadaSouto/Automatica/blob/master/Aprendizaje_profundo_robotica_adaptativa_datos_robot_3_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar deberéis subir los archivos de datos (lecturas.npy y velocidades.npy) a vuetra cuenta de drive, colgarlos directamente del directorio raíz para que os funcione el código más abajo. Los dos primeros bloques de código solo ejecutarlos una única vez\n"
      ],
      "metadata": {
        "id": "w4_mhFvF_2vw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWLP1srU81PX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "input (\"montado, pulsa para seguir y cargar los datos \")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos los datos, en principio esto sería suficiente con hacerlo una única vez....Se trata de datos grabados del Turtlebot (robot real) mientras seguía una pared, dado que la velocidad lineal es constante vamos a crear un modelo que aprenda a decidir la velocidad angular del robot en funcioń de lo que se percibe desde el láser."
      ],
      "metadata": {
        "id": "X7FPX58OAO5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"voy a cargar datos sensores \")\n",
        "sensores=np.load('/content/drive/MyDrive/lecturas.npy')\n",
        "print (\"cargado ...., ahora voy con velocidades\")\n",
        "velocidades=np.load('/content/drive/MyDrive/velocidades.npy')\n",
        "print (\"hecho \")"
      ],
      "metadata": {
        "id": "TxWUrcgf-4pt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b49db28-2d57-42f0-d750-2f831833dbd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "voy a cargar datos sensores \n",
            "cargado ...., ahora voy con velocidades\n",
            "hecho \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora normalizamos los datos, revisa como como lo hago, en principio esta celda solo se debería ejecutar una vez\n"
      ],
      "metadata": {
        "id": "v_Z73tL5BDUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#En primer lugar hacemos una inspeccion visual de dimensiones para comprobar que todo correcto\n",
        "print (\"dimension de velocidades \",velocidades.shape,\" y dimension \",velocidades.ndim)\n",
        "print (\"dimension de lecturas \",sensores.shape,\" y dimension \",sensores.ndim)\n",
        "\n",
        "\n",
        "sensores=sensores.astype('float32')\n",
        "velocidades=velocidades.astype('float32')\n",
        "\n",
        "#Invertimos los sensores para que tenga mas importancia lo que esta cerca\n",
        "#hacemos luego la normalizacion habitual\n",
        "sensores=np.reciprocal(sensores)\n",
        "for i in range(sensores.shape[1]):\n",
        "    sensores[:,i]=(sensores[:,i]-np.mean(sensores[:,i]))/np.std(sensores[:,i])\n",
        "    print (\"se ha normalizado \",i,\" el nuevo valor medio \",np.mean(sensores[:,i]),\" desviacion \",np.std(sensores[:,i]))\n",
        "\n",
        "\n",
        "velocidades_maximas=np.amax(velocidades, axis=0)\n",
        "velocidades_minimas=np.amin(velocidades, axis=0)\n",
        "print (\"velocidades_maximas \", velocidades_maximas)\n",
        "print (\"velocidades minimas \",velocidades_minimas)\n",
        "\n",
        "maximav=np.amax(velocidades[:,1])\n",
        "minimav=np.amin(velocidades[:,1])\n",
        "\n",
        "velocidades[:,1]=(velocidades[:,1]-minimav)/(maximav-minimav)\n",
        "print (\"se ha normalizado  angular el nuevo valor medio \",np.mean(velocidades[:,1]),\" desviacion \",np.std(velocidades[:,1]))\n",
        "print  (\"Ya he finalizado toda la normalizacion \")\n"
      ],
      "metadata": {
        "id": "H-fYAznXAgPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construimos los conjuntos de entrenamiento y test...."
      ],
      "metadata": {
        "id": "vd9bN4q7BmPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cardinal_entrena=(int)(round(sensores.shape[0]*(3/4)))\n",
        "print  (\"numero de patrones de entrenamiento \",cardinal_entrena)\n",
        "x_train=sensores[0:cardinal_entrena,:]\n",
        "y_train=velocidades[0:cardinal_entrena,1]\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "\n",
        "\n",
        "x_test=sensores[cardinal_entrena:sensores.shape[0],:]\n",
        "y_test=velocidades[cardinal_entrena:velocidades.shape[0],1]\n",
        "y_test=y_test.reshape(y_test.shape[0],1)\n",
        "\n",
        "print (\"shape de entradas entrenamiento \",x_train.shape)\n",
        "print (\"shape de salidas entrenamiento \",y_train.shape)\n",
        "print (\"shape de entradas test \",x_test.shape)\n",
        "print (\"shape de salidas test \",y_test.shape)"
      ],
      "metadata": {
        "id": "qwQwCKX0BV0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b8a713-e576-46ef-eaea-963e03525455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numero de patrones de entrenamiento  10070\n",
            "shape de entradas entrenamiento  (10070, 1438)\n",
            "shape de salidas entrenamiento  (10070, 1)\n",
            "shape de entradas test  (3357, 1438)\n",
            "shape de salidas test  (3357, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a crear una red profunda, es importante que te fijes en varias cosas:\n",
        "\n",
        "1. En primer lugar fíjate que tenemos que introducir tensores (numero de dimensiones=3)\n",
        "\n",
        "x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],y_train.shape[1],1)\n",
        "\n",
        "print (\"shape x_train \",x_train.shape,\"shape y_train \",y_train.shape)\n",
        "\n",
        "Ahora vamos a crear topologías imposibles!!!!, mira si eres capaz de entender la concatenación de redes, el profesor os lo expliará en clase\n",
        "\n"
      ],
      "metadata": {
        "id": "TMi5tQjjDBWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#definimos valores importantes\n",
        "epocas=200\n",
        "tamanho_batch=100\n",
        "\n",
        "\n",
        "capa_oculta_1=20\n",
        "capa_oculta_2=20\n",
        "capa_oculta_3=20\n",
        "#verbose indica lo que se ve durante el entrenamiento\n",
        "#By setting verbose 0, 1 or 2 you just say how do you want to 'see' the training progress for each epoch.\n",
        "#verbose=0 will show you nothing (silent)\n",
        "#verbose=1 will show you an animated progress bar\n",
        "#Verbose=2 (one line per epoch)\n",
        "opcion_muestra=1\n",
        "neuronas_salida=1\n",
        "\n",
        "division_validacion=0.2 #porcentaje de entrenamiento que se deja para validacion\n",
        "dimension=sensores.shape[1] #esto representa el numero de columnas del patron sensorial\n",
        "\n",
        "x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n",
        "y_train=y_train.reshape(y_train.shape[0],y_train.shape[1],1)\n",
        "print (\"shape x_train \",x_train.shape,\"shape y_train \",y_train.shape)\n",
        "\n",
        "\n",
        "#Ahora construimos el modelo de red neuronal\n",
        "input_shape=keras.layers.Input(shape=(x_train.shape[1],1))\n",
        "tower_1=keras.layers.MaxPool1D(5,strides=1)(input_shape)\n",
        "\n",
        "tower_2=keras.layers.MaxPool1D(3)(input_shape)\n",
        "\n",
        "tower_3=keras.layers.AveragePooling1D(pool_size=5,strides=1)(input_shape)\n",
        "capas_paralelas=keras.layers.concatenate([tower_1,tower_2,tower_3], axis=1)\n",
        "parte_primera=tf.keras.Model(inputs=input_shape, outputs=capas_paralelas)\n",
        "\n",
        "\n",
        "modelo=tf.keras.models.Sequential()\n",
        "modelo.add(parte_primera)\n",
        "\n",
        "\n",
        "modelo.add(keras.layers.Flatten())\n",
        "\n",
        "modelo.add(keras.layers.Dense(capa_oculta_1,name='capa_1',activation='tanh'))\n",
        "modelo.add(keras.layers.Dense(capa_oculta_2,name='capa_2',activation='tanh'))\n",
        "modelo.add(keras.layers.Dense(capa_oculta_3,name='capa_3',activation='relu',kernel_regularizer=l2(0.01)))\n",
        "modelo.add(keras.layers.Dense(neuronas_salida,name='capa_4',activation='relu',kernel_regularizer=l2(0.01)))\n",
        "#resumen del modelo\n",
        "modelo.summary()\n",
        "input (\"ha llegado el momento de entrenar ... \")\n",
        "\n",
        "modelo.compile(optimizer='adam',loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "#entrenamos el modelo\n",
        "modelo.fit(x_train,y_train,batch_size=tamanho_batch,epochs=epocas,verbose=opcion_muestra,validation_split=division_validacion)\n",
        "#evaluamos  el modelo\n",
        "\n",
        "entrenamiento_loss,entrenamiento_acc=modelo.evaluate(x_train,y_train)\n",
        "print (\"resultado sobre entrenamiento  \",entrenamiento_acc, \" loss \",entrenamiento_loss)\n",
        "\n",
        "x_test=x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n",
        "y_test=y_test.reshape(y_test.shape[0],y_test.shape[1],1)\n",
        "print (\"shape x_train \",x_test.shape,\"shape y_train \",y_test.shape)\n",
        "\n",
        "test_loss,test_acc=modelo.evaluate(x_test,y_test)\n",
        "print (\"resultado sobre test \",test_acc,\" loss \",test_loss)\n",
        "\n",
        "\n",
        "salida_test=modelo(x_test)\n",
        "print (salida_test.shape)\n",
        "input (\"pulsa para verificar\")\n",
        "\n",
        "for i in range (salida_test.shape[0]):\n",
        "    print (\"salida red \",(float)(salida_test[i]),\" salida deseada \",y_test[i])\n",
        "    if (i % 100 == 0):\n",
        "        input (\"pulsa para seguir ....\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t8CfmefOB0eb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}